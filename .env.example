# LLM Configuration
# LLM 모델 이름 (예: llama3.2, mistral, codellama 등)
LLM_MODEL=llama3.2

# LLM API Base URL
# 로컬 LLM 서버: http://localhost:11434/v1
# 사용자 정의 포트를 사용하는 경우: http://localhost:YOUR_PORT/v1
LLM_BASE_URL=http://localhost:11434/v1

# Temperature (0.0 - 2.0)
# 낮을수록 결정론적, 높을수록 창의적
TEMPERATURE=0.7

# MCP Server Configuration
# MCP 서버 베이스 URL (mcp-servers 프로젝트)
MCP_BASE_URL=https://localhost:22000

# MCP SSL 검증 (개발 환경에서는 false 사용)
MCP_VERIFY_SSL=false

# MCP Tools 사용 여부 (true/false)
USE_MCP_TOOLS=true

# API Server Configuration
# API 서버 호스트 (0.0.0.0 = 모든 인터페이스에서 접근 가능)
API_HOST=0.0.0.0

# API 서버 포트
API_PORT=23000

# WebSocket Server Configuration
# WebSocket 서버 URL (세션 검증용)
WEBSOCKET_SERVER_URL=http://localhost:21000

# Langfuse Configuration (LLM Observability)
# Langfuse 사용 여부 (true/false)
LANGFUSE_ENABLED=false

# Langfuse 서버 주소
LANGFUSE_BASE_URL=http://192.168.3.20:3000

# Langfuse 공개 키 (선택 사항 - Langfuse 서버에서 발급)
LANGFUSE_PUBLIC_KEY=

# Langfuse 비밀 키 (선택 사항 - Langfuse 서버에서 발급)
LANGFUSE_SECRET_KEY=

# 환경 구분 (development, staging, production)
LANGFUSE_TRACING_ENVIRONMENT=development

# Session Store Configuration
# 세션 저장소 타입 (memory | redis)
# memory: 단일 워커용, 인메모리 저장 (서버 재시작 시 손실)
# redis: 멀티 워커 지원, Redis 기반 저장 (영구 저장 가능)
SESSION_STORE_TYPE=memory

# 세션 TTL (Time To Live) - 초 단위
# 기본값: 1800초 (30분)
SESSION_TTL_SECONDS=1800

# Redis URL (SESSION_STORE_TYPE=redis 일 때 사용)
# Redis persistence를 끄려면: redis-server --save "" --appendonly no
REDIS_URL=redis://localhost:6379/0
